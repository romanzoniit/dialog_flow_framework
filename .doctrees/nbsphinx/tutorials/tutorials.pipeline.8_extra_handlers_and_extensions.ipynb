{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0531fdf",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# 8. Extra Handlers and Extensions\n",
    "\n",
    "The following tutorial shows how pipeline can be extended\n",
    "by global extra handlers and custom functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117badb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "__Installing dependencies__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee8ca66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T10:58:13.463912Z",
     "iopub.status.busy": "2023-04-07T10:58:13.463695Z",
     "iopub.status.idle": "2023-04-07T10:58:14.397473Z",
     "shell.execute_reply": "2023-04-07T10:58:14.396625Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: dff 0.3.2 does not provide the extra 'tutorials'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -q dff[tutorials]\n",
    "# Installs dff with dependencies for running tutorials\n",
    "# To install the minimal version of dff, use `pip install dff`\n",
    "# To install other options of dff, use `pip install dff[OPTION_NAME1,OPTION_NAME2]`\n",
    "# where OPTION_NAME can be one of the options from EXTRA_DEPENDENCIES.\n",
    "# e.g `pip install dff[ydb, mysql]` installs dff with dependencies for using Yandex Database and MySQL\n",
    "# EXTRA_DEPENDENCIES can be found in\n",
    "# https://github.com/deeppavlov/dialog_flow_framework/blob/dev/setup.py#L155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc393a1",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "__Running tutorial__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0df3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T10:58:14.401280Z",
     "iopub.status.busy": "2023-04-07T10:58:14.400702Z",
     "iopub.status.idle": "2023-04-07T10:58:15.034253Z",
     "shell.execute_reply": "2023-04-07T10:58:15.033552Z"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from dff.pipeline import (\n",
    "    Pipeline,\n",
    "    ComponentExecutionState,\n",
    "    GlobalExtraHandlerType,\n",
    "    ExtraHandlerRuntimeInfo,\n",
    "    ServiceRuntimeInfo,\n",
    "    ACTOR,\n",
    ")\n",
    "\n",
    "from dff.utils.testing.common import (\n",
    "    check_happy_path,\n",
    "    is_interactive_mode,\n",
    "    run_interactive_mode,\n",
    ")\n",
    "from dff.utils.testing.toy_script import HAPPY_PATH, TOY_SCRIPT\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b5946",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Pipeline functionality can be extended by global extra handlers.\n",
    "Global extra handlers are special extra handlers\n",
    "    that are called on some stages of pipeline execution.\n",
    "There are 4 types of global extra handlers:\n",
    "\n",
    "    * `BEFORE_ALL` is called before pipeline execution.\n",
    "    * `BEFORE` is called before each service and service group execution.\n",
    "    * `AFTER` is called after each service and service group execution.\n",
    "    * `AFTER_ALL` is called after pipeline execution.\n",
    "\n",
    "Global extra handlers have the same signature as regular extra handlers.\n",
    "Actually `BEFORE_ALL` and `AFTER_ALL`\n",
    "    are attached to root service group named 'pipeline',\n",
    "    so they return its runtime info\n",
    "\n",
    "All extra handlers warnings (see tutorial 7)\n",
    "are applicable to global extra handlers.\n",
    "Pipeline `add_global_extra_handler` function is used to register\n",
    "    global extra handlers. It accepts following arguments:\n",
    "\n",
    "* `global_extra_handler_type` (required) - A `GlobalExtraHandlerType` instance,\n",
    "    indicates extra handler type to add.\n",
    "* `extra_handler` (required) - The extra handler function itself.\n",
    "* `whitelist` - An optional list of paths, if it's not `None`\n",
    "                the extra handlers will be applied to\n",
    "                specified pipeline components only.\n",
    "* `blacklist` - An optional list of paths, if it's not `None`\n",
    "                the extra handlers will be applied to\n",
    "                all pipeline components except specified.\n",
    "\n",
    "Here basic functionality of `df-node-stats` library is emulated.\n",
    "Information about pipeline component execution time and\n",
    "    result is collected and printed to info log after pipeline execution.\n",
    "Pipeline consists of actor and 25 `long_service`s\n",
    "that run random amount of time between 0 and 0.05 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5503a6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T10:58:15.037669Z",
     "iopub.status.busy": "2023-04-07T10:58:15.037315Z",
     "iopub.status.idle": "2023-04-07T10:58:15.044984Z",
     "shell.execute_reply": "2023-04-07T10:58:15.044270Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "start_times = dict()  # Place to temporarily store service start times\n",
    "pipeline_info = dict()  # Pipeline information storage\n",
    "\n",
    "\n",
    "def before_all(_, __, info: ExtraHandlerRuntimeInfo):\n",
    "    global start_times, pipeline_info\n",
    "    now = datetime.now()\n",
    "    pipeline_info = {\"start_time\": now}\n",
    "    start_times = {info[\"component\"][\"path\"]: now}\n",
    "\n",
    "\n",
    "def before(_, __, info: ExtraHandlerRuntimeInfo):\n",
    "    start_times.update({info[\"component\"][\"path\"]: datetime.now()})\n",
    "\n",
    "\n",
    "def after(_, __, info: ExtraHandlerRuntimeInfo):\n",
    "    start_time = start_times[info[\"component\"][\"path\"]]\n",
    "    pipeline_info.update(\n",
    "        {\n",
    "            f\"{info['component']['path']}_duration\": datetime.now() - start_time,\n",
    "            f\"{info['component']['path']}_success\": info[\"component\"][\"execution_state\"].get(\n",
    "                info[\"component\"][\"path\"], ComponentExecutionState.NOT_RUN.name\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def after_all(_, __, info: ExtraHandlerRuntimeInfo):\n",
    "    pipeline_info.update({\"total_time\": datetime.now() - start_times[info[\"component\"][\"path\"]]})\n",
    "    logger.info(f\"Pipeline stats: {json.dumps(pipeline_info, indent=4, default=str)}\")\n",
    "\n",
    "\n",
    "async def long_service(_, __, info: ServiceRuntimeInfo):\n",
    "    timeout = random.randint(0, 5) / 100\n",
    "    logger.info(f\"Service {info['name']} is going to sleep for {timeout} seconds.\")\n",
    "    await asyncio.sleep(timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b6f5a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T10:58:15.047764Z",
     "iopub.status.busy": "2023-04-07T10:58:15.047557Z",
     "iopub.status.idle": "2023-04-07T10:58:15.051666Z",
     "shell.execute_reply": "2023-04-07T10:58:15.051003Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {\n",
    "    \"script\": TOY_SCRIPT,\n",
    "    \"start_label\": (\"greeting_flow\", \"start_node\"),\n",
    "    \"fallback_label\": (\"greeting_flow\", \"fallback_node\"),\n",
    "    \"components\": [\n",
    "        [long_service for _ in range(0, 25)],\n",
    "        ACTOR,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422be057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T10:58:15.054625Z",
     "iopub.status.busy": "2023-04-07T10:58:15.054413Z",
     "iopub.status.idle": "2023-04-07T10:58:15.357095Z",
     "shell.execute_reply": "2023-04-07T10:58:15.356357Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(user) >>> text='Hi'\n",
      " (bot) <<< text='Hi, how are you?'\n",
      "(user) >>> text='i'm fine, how are you?'\n",
      " (bot) <<< text='Good. What do you want to talk about?'\n",
      "(user) >>> text='Let's talk about music.'\n",
      " (bot) <<< text='Sorry, I can not talk about music now.'\n",
      "(user) >>> text='Ok, goodbye.'\n",
      " (bot) <<< text='bye'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(user) >>> text='Hi'\n",
      " (bot) <<< text='Hi, how are you?'\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(**pipeline_dict)\n",
    "\n",
    "pipeline.add_global_handler(GlobalExtraHandlerType.BEFORE_ALL, before_all)\n",
    "pipeline.add_global_handler(GlobalExtraHandlerType.BEFORE, before)\n",
    "pipeline.add_global_handler(GlobalExtraHandlerType.AFTER, after)\n",
    "pipeline.add_global_handler(GlobalExtraHandlerType.AFTER_ALL, after_all)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_happy_path(pipeline, HAPPY_PATH)\n",
    "    if is_interactive_mode():\n",
    "        run_interactive_mode(pipeline)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
